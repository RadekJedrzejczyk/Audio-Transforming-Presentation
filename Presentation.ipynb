{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c84cb-1cdc-46e7-a24a-fc2e8d3fea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pydub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e23027-61f4-49a5-a9fb-2be199fa3030",
   "metadata": {},
   "source": [
    "Z ```IPython``` dodamy widget, aby móc odtwarzać audio a następnie załadujemy przykładowy plik z ```librosa```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5473570-a2a2-4dcc-9bf6-0d75932bd316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "#sampling_rate=number of samples per second of audi\n",
    "#waveform saved as one-dimensional NumPy floating point array\n",
    "filename = librosa.example('nutcracker')\n",
    "waveform, sampling_rate = librosa.load(filename)\n",
    "Audio(data=waveform, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536e3f1-344e-4fb7-a8fc-7ca35c1a6e9a",
   "metadata": {},
   "source": [
    "Z użyciem biblioteki ```librosa``` wyznaczyć możemy tempo melodii oraz dokładne czasy (klatki) w których wybijany jest rytm. Typowo:\n",
    "- Wolne tempo: Balady, piosenki klasyczne, jazz, gdzie BPM wynosi około 60-80.\n",
    "- Średnie tempo: Wiele utworów pop, rock, gdzie BPM wynosi 100-120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94323e3a-d05e-4719-9a7c-d578fe7c6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENS EXAMPLE\n",
    "tempo, beat_frames = librosa.beat.beat_track(y=waveform, sr=sampling_rate)             \n",
    "print(f'Oszacowane tempo: {tempo} BPM')\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sampling_rate)\n",
    "print(f\"Sekundy w których jest wybijane: {beat_times}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4997bb-5d1c-47fc-9be2-d92b9dc5567c",
   "metadata": {},
   "source": [
    "Jeśli mamy wątpliwości co do tego czy nasze tempo zostało wyznaczone poprawnie możemy wykorzystać funkcję jego dynamicznego śledzenia - ```librosa.feature.tempo```. Parametr ```aggregate=None``` sprawia, że tempo wyznaczane jest osobno dla każdej klatki, a ```std_bpm``` informuje o odchyleniu standardowym BPM'ów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5d24d-5f9a-4da5-ba5a-b8199877a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_dynamic = librosa.feature.tempo(y=waveform, sr=sampling_rate, aggregate=None, std_bpm=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "times = librosa.times_like(tempo_dynamic, sr=sampling_rate)\n",
    "ax.plot(times, tempo_dynamic, label='Dynamic tempo estimate')\n",
    "ax.axhline(tempo, label='Static tempo estimate', color='r')\n",
    "ax.legend()\n",
    "ax.set(xlabel='Time (s)', ylabel='Tempo (BPM)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca6f29-0e0b-4b3f-ba17-e23adf28b671",
   "metadata": {},
   "source": [
    "Wyświetlić możemy również wykres na tle waveformu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23eea5-17ad-4d58-b199-c958b0898bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(waveform, sr=sampling_rate) #wyświetlanie fali dźwiękowej\n",
    "plt.vlines(librosa.frames_to_time(beat_frames), ymin=-1, ymax=1, color='r', alpha=0.7, label='Beats')\n",
    "plt.title(f'Tempo: {tempo[0]:.2f} BPM')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a185bd-4dc7-4307-ac09-f4c83f511b22",
   "metadata": {},
   "source": [
    "## Zmiana tempa i wysokości (pitch shifting) - manipulacja dźwiękiem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538ea41-ef78-4903-b9b2-90d1c0006239",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Hall_Of_Fame_(Official Instrumental).mp3'\n",
    "y, sr = librosa.load(filename)\n",
    "Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba44d78c-f67a-448d-b45f-b2e45097253e",
   "metadata": {},
   "source": [
    "Zmiana tempa zmienia szybkość odtwarzania dźwięku (przyspiesza lub spowalnia) bez zmiany wysokości dźwięku (tonu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce11af-be0b-4ab1-af65-e65fce695f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zwiększanie tempa o 50% (rate = 1.5) \n",
    "y_fast = librosa.effects.time_stretch(y, rate=1.5)\n",
    "Audio(data=y_fast, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ad591-bc72-4707-9397-823ce047027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zmniejszanie tempa o 50% (rate = 1.5) \n",
    "y_slow = librosa.effects.time_stretch(y, rate=0.5)\n",
    "Audio(data=y_slow, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26150fbf-ddc5-4027-b845-89241e740ee4",
   "metadata": {},
   "source": [
    "### Wykresy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d3a509-c4cc-4196-b71e-55dacc12cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(y_fast, sr=sr)\n",
    "plt.title('Przyspieszone tempo')\n",
    "plt.show()\n",
    "\n",
    "librosa.display.waveshow(y_slow, sr=sr)\n",
    "plt.title('Spowolnione tempo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a2c5b-1e80-4745-929c-6bded40eb37c",
   "metadata": {},
   "source": [
    "### Zmiana wysokości dźwięku (tonu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b2269-bcee-46ca-bc6d-1235d957d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pitched_up = librosa.effects.pitch_shift(y, sr=sr, n_steps=4)\n",
    "Audio(data=y_pitched_up, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63da17-4f8f-43db-b241-5878355cb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pitched_down = librosa.effects.pitch_shift(y, sr=sr, n_steps=-4)\n",
    "Audio(data=y_pitched_down, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576fd2d-5123-4b94-a4be-191bc1e66190",
   "metadata": {},
   "source": [
    "Ton wyższy odpowiada wyższej częstotliwości (więcej drgań na sekundę).\n",
    "Ton niższy odpowiada niższej częstotliwości (mniej drgań na sekundę)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962672f-766d-4231-810c-499e11be9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(y_pitched_up, sr=sr)\n",
    "plt.title('Zwiększony ton')\n",
    "plt.show()\n",
    "\n",
    "librosa.display.waveshow(y_pitched_down, sr=sr)\n",
    "plt.title('Zmniejszony ton')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b22db-b245-4722-af43-91bb480a740b",
   "metadata": {},
   "source": [
    "## Obliczanie spektrum chromatycznego (Chroma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d4e2e-6b3b-4a19-86db-b8b997283af2",
   "metadata": {},
   "source": [
    "Chromagram to narzędzie, które analizuje, jakie dźwięki (o jakich częstotliwościach) są obecne w danym momencie w utworze. Chromagram będzie pokazywał, w którym momencie utworu pojawiają się określone dźwięki o określonych częstotliwościach i jak intensywnie są obecne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c1d7b-90c3-4c56-8b05-66b608ad32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', sr=sr)\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram (spektrum chromatyczne)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0093c-fb32-43d1-a00c-6150740c7a66",
   "metadata": {},
   "source": [
    "## Wykrywanie tonacji (Tonality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc63e61-051d-424d-9319-49f307647fa4",
   "metadata": {},
   "source": [
    "Chromagram CQT jest bardziej zaawansowaną wersją zwykłego chromagramu i wykorzystuje transformatę CQT (constant-Q transform), która lepiej odwzorowuje muzyczne tonacje i akordy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b054c-77bf-435d-bded-2e241d796026",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(chroma_cqt, y_axis='chroma', x_axis='time', sr=sr)\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram CQT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d714c22-d151-4cb6-baec-660ec9b0c897",
   "metadata": {},
   "source": [
    "## Obliczanie tempa utworu (Beat Tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d96f22-f40d-4c90-9b15-8d4d466fb2f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5c8bd-bb54-4a21-b188-218673701779",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8adf3e-0930-44e0-83b7-2dd932cb0c0a",
   "metadata": {},
   "source": [
    "WNIOSEK: tempo jest szybkie, więc utwór ma energiczny rytm. Występują gęste linie (czyli często występują bity), czyli jest szybsze tempo utworu (więcej bitów na sekundę)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5513c66-d41f-4401-8d61-ee8dd74bca84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_louder = y * 5  # Podnosi głośność 5 razy\n",
    "# Znormalizowanie do zakresu [-1, 1], aby zapobiec przesterowaniu\n",
    "y_louder = np.clip(y_louder, -1.0, 1.0)\n",
    "Audio(data=y_louder, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f357fb9-5b09-4b31-8807-13a5e838bb2d",
   "metadata": {},
   "source": [
    "## Zmiana głośności (Gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe9fac6-822d-40c3-8e53-24cbb06a8cf0",
   "metadata": {},
   "source": [
    "Original advance example and comments (I haven't went through it yet) from librosa documentation            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e7e10-a0a9-4b94-a4e1-2ecf38496a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_quieter = y * 0.1  # Zmniejszenie głośności\n",
    "\n",
    "# Przycinanie do zakresu [-1, 1], aby uniknąć zniekształceń\n",
    "y_quieter = np.clip(y_quieter, -1.0, 1.0)\n",
    "Audio(data=y_quieter, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658ea04-b09a-45e3-8f56-b2898101c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.waveshow(y_louder, sr=sr)\n",
    "plt.title('Zwiększona głośność')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.waveshow(y_quieter, sr=sr)\n",
    "plt.title('Zmniejszona głośność')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760483ef-65c1-48e6-b888-9e4ed09e6faf",
   "metadata": {},
   "source": [
    "## Dodanie efektu reverb (Reverb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7660b-cd54-42b6-a48d-4764b8ca4e82",
   "metadata": {},
   "source": [
    "Dodanie pogłosu do dźwięku, co sprawia, że dźwięk staje się bardziej przestrzenny i pełny. Dodanie pogłosu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be276d34-2b15-4a51-bd98-ddc3213156b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reverb = librosa.effects.preemphasis(y)\n",
    "Audio(data=y_reverb, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11529d0a-8bca-47ec-9b48-98ac8ebee940",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305fe997-093a-4e2f-ba76-27635ec06b59",
   "metadata": {},
   "source": [
    "## Usunięcie ciszy na początku i na końcu audio )\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba43a4d-4933-4cfe-9a8f-8331b1320221",
   "metadata": {},
   "source": [
    "Usuwa ciszę na początku i końcu pliku audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d0743-97ab-4ec4-8a1a-9ab8bce44a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trimmed, _ = librosa.effects.trim(y)\n",
    "Audio(data=y_trimmed, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50577203-a229-47b5-a352-41b7d7a5fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f6cf8-37c6-40aa-b993-0705944db41b",
   "metadata": {},
   "source": [
    "## Wykrywanie transjentów (transient detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4b62e-b05c-4668-a203-8169cfb34d40",
   "metadata": {},
   "source": [
    "Transjenty to krótkotrwałe zmiany w dźwięku, np. uderzenia bębna czy inne nagłe zmiany w głośności..\n",
    "Metoda ta wykrywa momenty, w których następuje nagła zmiana w dźwięku (np. uderzenie w perkusję)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7943d1-0f85-46c3-b0a3-6a884d41fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "transients = librosa.onset.onset_detect(y=y, sr=sr, units='time')\n",
    "plt.figure(figsize=(10, 6))\n",
    "librosa.display.waveshow(y, sr=sr, alpha=0.5)\n",
    "plt.vlines(transients, ymin=-1, ymax=1, color='r', alpha=0.6, label='Transjenty')\n",
    "plt.title('Wykrywanie transjentów')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ddcab-aac4-4627-b7dd-f329ad2e37b0",
   "metadata": {},
   "source": [
    "## Rodzielanie ścieżek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626df69-87c2-4881-b579-733e1de26a5d",
   "metadata": {},
   "source": [
    "Będziemy chcieli oddzielić ścieżkę perkusyjną od melodii, w tym celu najpierw zastosujemy krótkoczasową transformatę Fouriera. Przeprowadza ona zasadniczo klasyczną tranformację w małych oknach czasowych wyznaczonych na całym naszym sygnale. W jej efekcie dostajemy informację o natężeniu w różnych częstotliwościach na naszym sygnale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae70bdd-7366-4e5e-8c79-86afa8be3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = librosa.stft(waveform)\n",
    "D_harmonic, D_percussive = librosa.decompose.hpss(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4756d-569d-4197-b1e3-9a3520e21e4d",
   "metadata": {},
   "source": [
    "Wyświetlimy teraz historiogramy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4204ec8-d8db-4987-af43-fa9c14432994",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = np.max(np.abs(D))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Full spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='Harmonic spectrogram')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='Percussive spectrogram')\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da28544-189e-480c-ad10-165b6b4ce8a0",
   "metadata": {},
   "source": [
    "Odtwórzmy warstwę melodyczną. W tym celu musimy wrócić z przetransformowanego sygnału do normalnego - wykonać odwrotną krótkoczasową transformację Fouriera. Działanie to wykonuje funkcja ``` librosa.istft ```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef47b3-452d-46e1-8677-13fd86833139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_harmonic = librosa.istft(D_harmonic, length=len(waveform))\n",
    "Audio(data=y_harmonic, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba3b4a-3024-4bce-96f7-8138e3174466",
   "metadata": {},
   "source": [
    "Oraz perkusyjną"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15027eb6-d26e-43ae-b7a1-a13d4cc21fce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "y_percussive = librosa.istft(D_percussive, length=len(waveform))\n",
    "Audio(data=y_percussive, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b68bf-daba-4874-ac67-279718a08a0b",
   "metadata": {},
   "source": [
    "Domyślna funkcja stft stara się przypisać sygnały jednoznacznie do jednej albo drugiej warstwy, co sprawia że nie najlepiej radzi sobie z szumami i dźwiękami, które nie należą jednoznacznie do żadnej grupy. W tym celu zastosować możemy pewien margines ```margin``` (domyślnie ```margin=1```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b71328-f8d7-4db4-973d-dfa28fa08169",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_harmonic2, D_percussive2 = librosa.decompose.hpss(D, margin=2)\n",
    "D_harmonic4, D_percussive4 = librosa.decompose.hpss(D, margin=4)\n",
    "D_harmonic8, D_percussive8 = librosa.decompose.hpss(D, margin=8)\n",
    "D_harmonic16, D_percussive16 = librosa.decompose.hpss(D, margin=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c0547-d159-45b4-808a-a1dd99f87265",
   "metadata": {},
   "source": [
    "Wyświetlając spektrogramy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042cfa6-70f9-4047-a28c-c3018e68b81b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=2, sharex=True, sharey=True, figsize=(10, 10))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0, 0])\n",
    "ax[0, 0].set(title='Harmonic')\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0, 1])\n",
    "ax[0, 1].set(title='Percussive')\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic2), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1, 0])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive2), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1, 1])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic4), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2, 0])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive4), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2, 1])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic8), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[3, 0])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive8), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[3, 1])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic16), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[4, 0])\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive16), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[4, 1])\n",
    "\n",
    "for i in range(5):\n",
    "    ax[i, 0].set(ylabel='margin={:d}'.format(2**i))\n",
    "    ax[i, 0].label_outer()\n",
    "    ax[i, 1].label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3774f3-e309-4b05-9232-a420e7b8ca51",
   "metadata": {},
   "source": [
    "Zmiany są wyraźnie widoczne na spektrogramach. Odsłuchać możemy dla przykładu ```margin=8```. W sytuacji gdzie ścieżka perkusyjna jest mocniej zarysowana różnicę będą bardziej widoczne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b358b8c-8af9-43a7-81ee-835be3076180",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_harmonic8 = librosa.istft(D_harmonic8, length=len(waveform))\n",
    "Audio(data=y_harmonic8, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210221d-3e24-462f-b94c-68fc69ea28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_percussive8 = librosa.istft(D_percussive8, length=len(waveform))\n",
    "Audio(data=y_percussive8, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49cb0e-f0b3-480c-9777-771dfab40160",
   "metadata": {},
   "source": [
    "Inną funkcjonalnością, która może się przydać jest oddzielanie wokalu. Obliczamy spektrogram oraz odtworzymy analizowany fragment dźwięku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bc639-bdc1-462c-93de-82d906631f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform2, sampling_rate = librosa.load(librosa.ex('fishin'), duration=120)\n",
    "S_full, phase = librosa.magphase(librosa.stft(waveform2))\n",
    "Audio(data=waveform2[10*sampling_rate:15*sampling_rate], rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6e2ea-0ccb-4d3c-950d-8451c4dd539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = slice(*librosa.time_to_frames([10, 15], sr=sampling_rate))\n",
    "fig, ax = plt.subplots()\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(S_full[:, idx], ref=np.max),\n",
    "                         y_axis='log', x_axis='time', sr=sampling_rate, ax=ax)\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59419c16-4818-4962-b384-30f7581c3a32",
   "metadata": {},
   "source": [
    "Przeprowadzamy analizę podobieństwa sygnałów - jako metrykę wykorzystamy funkcję cos, poszukjemy sygnałóœ podobnych oddzielonych o minimum 2 sekundy (aby uniknąć lokalnego podobieństwa). Tym sposobem oddzialamy powtarzalne dźwięki (melodię)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd06ec-1edf-4716-927f-baa6ede1b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_filter = librosa.decompose.nn_filter(S_full,\n",
    "                                       aggregate=np.median,\n",
    "                                       metric='cosine',\n",
    "                                       width=int(librosa.time_to_frames(2, sr=sampling_rate)))\n",
    "\n",
    "# upewniamy się, że filtr nie jest większy niż pełny sygnał\n",
    "S_filter = np.minimum(S_full, S_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e148d86d-78f8-419c-95ce-9993a3795683",
   "metadata": {},
   "source": [
    "Jak poprzednio możemy zmiękczyć nasz rodział wprowadzając pewien margines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc2b5a-52e7-4a60-be17-2af90a2c6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the margins need not be equal for foreground and background separation\n",
    "margin_i, margin_v = 2, 10\n",
    "power = 2\n",
    "\n",
    "mask_i = librosa.util.softmask(S_filter,\n",
    "                               margin_i * (S_full - S_filter),\n",
    "                               power=power)\n",
    "\n",
    "mask_v = librosa.util.softmask(S_full - S_filter,\n",
    "                               margin_v * S_filter,\n",
    "                               power=power)\n",
    "\n",
    "#mnożymy sygnał i zmiękczającą maskę\n",
    "\n",
    "S_foreground = mask_v * S_full\n",
    "S_background = mask_i * S_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77956a5-fa51-43c5-a4a8-ac1f626def2f",
   "metadata": {},
   "source": [
    "Narysujmy nasze spektrogramy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf5e03-09e1-42f8-aed8-9f2663003b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sphinx_gallery_thumbnail_number = 2\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(S_full[:, idx], ref=np.max),\n",
    "                         y_axis='log', x_axis='time', sr=sampling_rate, ax=ax[0])\n",
    "ax[0].set(title='Full spectrum')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S_background[:, idx], ref=np.max),\n",
    "                         y_axis='log', x_axis='time', sr=sampling_rate, ax=ax[1])\n",
    "ax[1].set(title='Background')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S_foreground[:, idx], ref=np.max),\n",
    "                         y_axis='log', x_axis='time', sr=sampling_rate, ax=ax[2])\n",
    "ax[2].set(title='Foreground')\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216d879-4f0b-438b-a057-19bbc0acc021",
   "metadata": {},
   "source": [
    "Odtwórzmy warstwę z wokalem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8bc48b-67e2-4132-9dc6-9c2937455bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_foreground = librosa.istft(S_foreground * phase)\n",
    "# Play back a 5-second excerpt with vocals\n",
    "Audio(data=y_foreground[10*sampling_rate:15*sampling_rate], rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc49c7-7173-48a4-aeea-260ad010903b",
   "metadata": {},
   "source": [
    "oraz warstwę z tłem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897be92-358f-4918-86c2-5b3d0f362b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_background = librosa.istft(S_background*phase)\n",
    "Audio(data=y_background[10*sampling_rate:15*sampling_rate], rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f277cd8-63c8-4d0d-81b5-0e9c45653182",
   "metadata": {},
   "source": [
    "Rozdział nie jest idealny - w praktyce kluczowe jest dobranie odpowiednich wartości filtrów dla każdego indywidualnego przypadku. Możemy również zastosować wielokrotne rodzielanie, aby wyodrębnić nasz sygnał stopniowo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6235b664-d6d9-4e04-8e95-1a3e9a7ab4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
